#!/usr/bin/env python3
"""
Comprehensive Security and Performance Testing Script

This script tests all the security hardening and performance monitoring features
implemented in the VIN telematics system.

Features Tested:
- Rate limiting functionality
- Input sanitization and validation
- Security headers
- Audit logging
- Caching performance
- Prometheus metrics
- Circuit breaker patterns
- CORS protection
"""

import asyncio
import aiohttp
import time
import json
import sys
from typing import Dict, List, Any
from datetime import datetime

class SecurityPerformanceTestSuite:
    """Comprehensive test suite for security and performance features"""
    
    def __init__(self, base_url: str = "http://localhost:8000"):
        self.base_url = base_url
        self.test_results = {
            "security_tests": {},
            "performance_tests": {},
            "overall_score": 0,
            "timestamp": datetime.utcnow().isoformat()
        }
        self.session = None
    
    async def setup(self):
        """Initialize test session"""
        self.session = aiohttp.ClientSession()
        print("ğŸ”§ Test session initialized")
    
    async def cleanup(self):
        """Cleanup test session"""
        if self.session:
            await self.session.close()
        print("ğŸ§¹ Test session cleaned up")
    
    async def test_rate_limiting(self) -> Dict[str, Any]:
        """Test rate limiting functionality"""
        print("\nğŸ›¡ï¸  Testing Rate Limiting...")
        
        results = {
            "passed": False,
            "details": {},
            "score": 0
        }
        
        try:
            # Test VIN analysis rate limiting (10/minute)
            vin_endpoint = f"{self.base_url}/api/v1/vin-telematics/vin/analyze"
            
            # Make rapid requests to trigger rate limiting
            rate_limit_triggered = False
            requests_made = 0
            
            for i in range(15):  # Exceed the 10/minute limit
                try:
                    async with self.session.post(
                        vin_endpoint,
                        json={"vin": "5YJ3E1EA1NF123456"},
                        headers={"Authorization": "Bearer demo_token"}
                    ) as response:
                        requests_made += 1
                        if response.status == 429:
                            rate_limit_triggered = True
                            rate_limit_response = await response.json()
                            print(f"âœ… Rate limit triggered after {requests_made} requests")
                            results["details"]["rate_limit_response"] = rate_limit_response
                            break
                        await asyncio.sleep(0.1)  # Small delay between requests
                except Exception as e:
                    print(f"âš ï¸  Request {i+1} failed: {str(e)}")
            
            if rate_limit_triggered:
                results["passed"] = True
                results["score"] = 100
                results["details"]["requests_before_limit"] = requests_made
                print("âœ… Rate limiting working correctly")
            else:
                results["details"]["error"] = "Rate limiting not triggered"
                print("âŒ Rate limiting not working")
        
        except Exception as e:
            results["details"]["error"] = str(e)
            print(f"âŒ Rate limiting test failed: {str(e)}")
        
        return results
    
    async def test_input_sanitization(self) -> Dict[str, Any]:
        """Test input sanitization and validation"""
        print("\nğŸ§¹ Testing Input Sanitization...")
        
        results = {
            "passed": False,
            "details": {},
            "score": 0
        }
        
        try:
            # Test malicious VIN inputs
            malicious_inputs = [
                "<script>alert('xss')</script>",
                "'; DROP TABLE vehicles; --",
                "../../../etc/passwd",
                "javascript:alert(1)",
                "AAAAAAAAAAAAAAAAA<script>",  # 17 chars with script
                "1" * 100,  # Too long
                "SHORT",  # Too short
                "5YJ3E1EA1NF12345O",  # Contains invalid char 'O'
            ]
            
            sanitization_working = 0
            total_tests = len(malicious_inputs)
            
            for malicious_input in malicious_inputs:
                try:
                    async with self.session.post(
                        f"{self.base_url}/api/v1/vin-telematics/vin/analyze",
                        json={"vin": malicious_input},
                        headers={"Authorization": "Bearer demo_token"}
                    ) as response:
                        if response.status == 400:  # Should be rejected
                            sanitization_working += 1
                            response_data = await response.json()
                            print(f"âœ… Malicious input rejected: {malicious_input[:20]}...")
                        else:
                            print(f"âš ï¸  Malicious input not rejected: {malicious_input[:20]}...")
                except Exception as e:
                    print(f"âš ï¸  Error testing input: {str(e)}")
            
            success_rate = (sanitization_working / total_tests) * 100
            results["score"] = int(success_rate)
            results["details"]["success_rate"] = success_rate
            results["details"]["tests_passed"] = sanitization_working
            results["details"]["total_tests"] = total_tests
            
            if success_rate >= 80:
                results["passed"] = True
                print(f"âœ… Input sanitization working: {success_rate:.1f}% success rate")
            else:
                print(f"âŒ Input sanitization insufficient: {success_rate:.1f}% success rate")
        
        except Exception as e:
            results["details"]["error"] = str(e)
            print(f"âŒ Input sanitization test failed: {str(e)}")
        
        return results
    
    async def test_security_headers(self) -> Dict[str, Any]:
        """Test security headers"""
        print("\nğŸ”’ Testing Security Headers...")
        
        results = {
            "passed": False,
            "details": {},
            "score": 0
        }
        
        try:
            async with self.session.get(f"{self.base_url}/health") as response:
                headers = dict(response.headers)
                
                required_headers = [
                    "X-Content-Type-Options",
                    "X-Frame-Options", 
                    "X-XSS-Protection",
                    "Strict-Transport-Security",
                    "Referrer-Policy"
                ]
                
                headers_present = 0
                for header in required_headers:
                    if header in headers:
                        headers_present += 1
                        print(f"âœ… {header}: {headers[header]}")
                    else:
                        print(f"âŒ Missing header: {header}")
                
                success_rate = (headers_present / len(required_headers)) * 100
                results["score"] = int(success_rate)
                results["details"]["headers_present"] = headers_present
                results["details"]["total_headers"] = len(required_headers)
                results["details"]["success_rate"] = success_rate
                results["details"]["headers"] = {h: headers.get(h) for h in required_headers}
                
                if success_rate >= 80:
                    results["passed"] = True
                    print(f"âœ… Security headers: {success_rate:.1f}% complete")
                else:
                    print(f"âŒ Security headers insufficient: {success_rate:.1f}% complete")
        
        except Exception as e:
            results["details"]["error"] = str(e)
            print(f"âŒ Security headers test failed: {str(e)}")
        
        return results
    
    async def test_cors_protection(self) -> Dict[str, Any]:
        """Test CORS protection"""
        print("\nğŸŒ Testing CORS Protection...")
        
        results = {
            "passed": False,
            "details": {},
            "score": 0
        }
        
        try:
            # Test valid origin
            valid_origin = "http://localhost:3000"
            async with self.session.options(
                f"{self.base_url}/health",
                headers={"Origin": valid_origin}
            ) as response:
                if response.status == 200:
                    cors_headers = dict(response.headers)
                    results["details"]["valid_origin_allowed"] = True
                    print(f"âœ… Valid origin allowed: {valid_origin}")
                else:
                    results["details"]["valid_origin_allowed"] = False
                    print(f"âŒ Valid origin rejected: {valid_origin}")
            
            # Test invalid origin - Note: This might not work as expected in dev mode
            # since CORS middleware might allow all origins for development
            invalid_origin = "http://malicious-site.com"
            try:
                async with self.session.options(
                    f"{self.base_url}/health",
                    headers={"Origin": invalid_origin}
                ) as response:
                    if response.status == 403:
                        results["details"]["invalid_origin_blocked"] = True
                        print(f"âœ… Invalid origin blocked: {invalid_origin}")
                    else:
                        results["details"]["invalid_origin_blocked"] = False
                        print(f"âš ï¸  Invalid origin not explicitly blocked (may be in dev mode)")
            except Exception:
                results["details"]["invalid_origin_blocked"] = True
                print(f"âœ… Invalid origin blocked (connection refused)")
            
            # Score based on valid origin working
            if results["details"].get("valid_origin_allowed", False):
                results["passed"] = True
                results["score"] = 85  # Partial score since invalid origin blocking is complex
                print("âœ… CORS protection working (valid origins allowed)")
            else:
                results["score"] = 0
                print("âŒ CORS protection not working")
        
        except Exception as e:
            results["details"]["error"] = str(e)
            print(f"âŒ CORS protection test failed: {str(e)}")
        
        return results
    
    async def test_caching_performance(self) -> Dict[str, Any]:
        """Test caching performance"""
        print("\nâš¡ Testing Caching Performance...")
        
        results = {
            "passed": False,
            "details": {},
            "score": 0
        }
        
        try:
            test_vin = "5YJ3E1EA1NF123456"
            endpoint = f"{self.base_url}/api/v1/vin-telematics/vin/analyze"
            
            # First request (should be slow - cache miss)
            start_time = time.time()
            async with self.session.post(
                endpoint,
                json={"vin": test_vin},
                headers={"Authorization": "Bearer demo_token"}
            ) as response:
                first_response_time = time.time() - start_time
                first_data = await response.json()
            
            print(f"ğŸ“Š First request time: {first_response_time:.3f}s")
            
            # Wait a moment then make second request (should be faster - cache hit)
            await asyncio.sleep(0.5)
            
            start_time = time.time()
            async with self.session.post(
                endpoint,
                json={"vin": test_vin},
                headers={"Authorization": "Bearer demo_token"}
            ) as response:
                second_response_time = time.time() - start_time
                second_data = await response.json()
            
            print(f"ğŸ“Š Second request time: {second_response_time:.3f}s")
            
            # Calculate performance improvement
            if first_response_time > 0:
                improvement = ((first_response_time - second_response_time) / first_response_time) * 100
                results["details"]["first_request_time"] = first_response_time
                results["details"]["second_request_time"] = second_response_time
                results["details"]["performance_improvement"] = improvement
                results["details"]["cached_indicated"] = second_data.get("cached", False)
                
                if improvement > 10 or second_data.get("cached", False):  # At least 10% improvement or cache indicated
                    results["passed"] = True
                    results["score"] = min(100, int(improvement * 2))  # Score based on improvement
                    print(f"âœ… Caching working: {improvement:.1f}% performance improvement")
                else:
                    results["score"] = 25
                    print(f"âš ï¸  Caching may not be working: {improvement:.1f}% improvement")
            else:
                results["details"]["error"] = "Response time too fast to measure"
                print("âš ï¸  Response times too fast to measure caching effect")
        
        except Exception as e:
            results["details"]["error"] = str(e)
            print(f"âŒ Caching performance test failed: {str(e)}")
        
        return results
    
    async def test_metrics_endpoint(self) -> Dict[str, Any]:
        """Test Prometheus metrics endpoint"""
        print("\nğŸ“Š Testing Metrics Endpoint...")
        
        results = {
            "passed": False,
            "details": {},
            "score": 0
        }
        
        try:
            async with self.session.get(f"{self.base_url}/metrics") as response:
                if response.status == 200:
                    metrics_data = await response.text()
                    
                    # Check for expected metrics
                    expected_metrics = [
                        "http_requests_total",
                        "http_request_duration_seconds",
                        "vin_decodes_total",
                        "cache_operations_total",
                        "active_requests"
                    ]
                    
                    metrics_found = 0
                    for metric in expected_metrics:
                        if metric in metrics_data:
                            metrics_found += 1
                            print(f"âœ… Metric found: {metric}")
                        else:
                            print(f"âŒ Metric missing: {metric}")
                    
                    success_rate = (metrics_found / len(expected_metrics)) * 100
                    results["score"] = int(success_rate)
                    results["details"]["metrics_found"] = metrics_found
                    results["details"]["total_metrics"] = len(expected_metrics)
                    results["details"]["success_rate"] = success_rate
                    results["details"]["response_size"] = len(metrics_data)
                    
                    if success_rate >= 80:
                        results["passed"] = True
                        print(f"âœ… Metrics endpoint working: {success_rate:.1f}% metrics present")
                    else:
                        print(f"âŒ Metrics endpoint incomplete: {success_rate:.1f}% metrics present")
                else:
                    results["details"]["status_code"] = response.status
                    print(f"âŒ Metrics endpoint returned {response.status}")
        
        except Exception as e:
            results["details"]["error"] = str(e)
            print(f"âŒ Metrics endpoint test failed: {str(e)}")
        
        return results
    
    async def test_audit_logging(self) -> Dict[str, Any]:
        """Test audit logging functionality"""
        print("\nğŸ“ Testing Audit Logging...")
        
        results = {
            "passed": False,
            "details": {},
            "score": 0
        }
        
        try:
            # Make a request that should generate audit logs
            async with self.session.post(
                f"{self.base_url}/api/v1/vin-telematics/vin/analyze",
                json={"vin": "5YJ3E1EA1NF123456"},
                headers={"Authorization": "Bearer demo_token"}
            ) as response:
                if response.status in [200, 400, 429]:  # Any valid response
                    print("âœ… Request made for audit logging")
                    
                    # Check if audit log endpoint exists
                    async with self.session.get(
                        f"{self.base_url}/security/audit-log"
                    ) as audit_response:
                        if audit_response.status == 200:
                            audit_data = await audit_response.json()
                            
                            if "audit_entries" in audit_data:
                                results["passed"] = True
                                results["score"] = 100
                                results["details"]["audit_entries_count"] = len(audit_data["audit_entries"])
                                print(f"âœ… Audit logging working: {len(audit_data['audit_entries'])} entries found")
                            else:
                                results["score"] = 50
                                print("âš ï¸  Audit endpoint exists but no entries structure")
                        else:
                            results["score"] = 25
                            print(f"âš ï¸  Audit endpoint returned {audit_response.status}")
                else:
                    print(f"âš ï¸  Test request failed with {response.status}")
        
        except Exception as e:
            results["details"]["error"] = str(e)
            print(f"âŒ Audit logging test failed: {str(e)}")
        
        return results
    
    async def run_all_tests(self) -> Dict[str, Any]:
        """Run all security and performance tests"""
        print("ğŸš€ Starting Comprehensive Security & Performance Test Suite")
        print("=" * 70)
        
        await self.setup()
        
        try:
            # Security Tests
            print("\nğŸ›¡ï¸  SECURITY TESTS")
            print("-" * 30)
            
            self.test_results["security_tests"]["rate_limiting"] = await self.test_rate_limiting()
            self.test_results["security_tests"]["input_sanitization"] = await self.test_input_sanitization()
            self.test_results["security_tests"]["security_headers"] = await self.test_security_headers()
            self.test_results["security_tests"]["cors_protection"] = await self.test_cors_protection()
            self.test_results["security_tests"]["audit_logging"] = await self.test_audit_logging()
            
            # Performance Tests
            print("\nâš¡ PERFORMANCE TESTS")
            print("-" * 30)
            
            self.test_results["performance_tests"]["caching_performance"] = await self.test_caching_performance()
            self.test_results["performance_tests"]["metrics_endpoint"] = await self.test_metrics_endpoint()
            
            # Calculate overall score
            all_tests = []
            for category in ["security_tests", "performance_tests"]:
                for test_name, test_result in self.test_results[category].items():
                    all_tests.append(test_result["score"])
            
            if all_tests:
                self.test_results["overall_score"] = sum(all_tests) / len(all_tests)
            
            # Generate report
            self.generate_report()
            
        finally:
            await self.cleanup()
        
        return self.test_results
    
    def generate_report(self):
        """Generate comprehensive test report"""
        print("\n" + "=" * 70)
        print("ğŸ“Š COMPREHENSIVE SECURITY & PERFORMANCE REPORT")
        print("=" * 70)
        
        overall_score = self.test_results["overall_score"]
        
        if overall_score >= 90:
            grade = "ğŸ¥‡ EXCELLENT"
            status = "âœ… PRODUCTION READY"
        elif overall_score >= 75:
            grade = "ğŸ¥ˆ GOOD"
            status = "âœ… MOSTLY READY"
        elif overall_score >= 60:
            grade = "ğŸ¥‰ FAIR"
            status = "âš ï¸  NEEDS IMPROVEMENT"
        else:
            grade = "âŒ POOR"
            status = "âŒ NOT READY"
        
        print(f"\nğŸ¯ OVERALL SCORE: {overall_score:.1f}/100")
        print(f"ğŸ“ˆ GRADE: {grade}")
        print(f"ğŸš€ STATUS: {status}")
        
        print(f"\nğŸ“‹ SECURITY TEST RESULTS:")
        for test_name, result in self.test_results["security_tests"].items():
            status_icon = "âœ…" if result["passed"] else "âŒ"
            print(f"   {status_icon} {test_name.replace('_', ' ').title()}: {result['score']}/100")
        
        print(f"\nğŸ“‹ PERFORMANCE TEST RESULTS:")
        for test_name, result in self.test_results["performance_tests"].items():
            status_icon = "âœ…" if result["passed"] else "âŒ"
            print(f"   {status_icon} {test_name.replace('_', ' ').title()}: {result['score']}/100")
        
        # Key recommendations
        print(f"\nğŸ”§ KEY RECOMMENDATIONS:")
        failed_tests = []
        for category in ["security_tests", "performance_tests"]:
            for test_name, result in self.test_results[category].items():
                if not result["passed"]:
                    failed_tests.append(test_name.replace("_", " ").title())
        
        if failed_tests:
            for test in failed_tests:
                print(f"   ğŸ”´ Fix {test}")
        else:
            print("   ğŸ‰ All tests passed! System is well-secured and optimized.")
        
        print(f"\nğŸ“ˆ NEXT STEPS:")
        if overall_score < 90:
            print("   1. Address failed test cases")
            print("   2. Implement missing security features")
            print("   3. Optimize performance bottlenecks")
            print("   4. Re-run tests to verify improvements")
        else:
            print("   1. Monitor system performance in production")
            print("   2. Set up alerting for security events")
            print("   3. Regular security and performance audits")
        
        print("\n" + "=" * 70)

async def main():
    """Main test runner"""
    if len(sys.argv) > 1:
        base_url = sys.argv[1]
    else:
        base_url = "http://localhost:8000"
    
    print(f"ğŸ¯ Testing server: {base_url}")
    
    test_suite = SecurityPerformanceTestSuite(base_url)
    results = await test_suite.run_all_tests()
    
    # Save results to file
    with open("security_performance_test_results.json", "w") as f:
        json.dump(results, f, indent=2, default=str)
    
    print(f"\nğŸ“ Detailed results saved to: security_performance_test_results.json")
    
    # Exit with error code if tests failed
    overall_score = results.get("overall_score", 0)
    if overall_score < 75:
        sys.exit(1)
    else:
        sys.exit(0)

if __name__ == "__main__":
    asyncio.run(main()) 